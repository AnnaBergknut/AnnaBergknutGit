{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Assigment 2\n",
    "Spambase, Anna Bergknut, DVAMI21\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as mpl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import scipy as scp\n",
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "# import time\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold, train_test_split\n",
    "\n",
    "from scipy.stats import friedmanchisquare, rankdata, chi2, kruskal\n",
    "from sklearn.model_selection import cross_val_score, KFold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"spambase.data\"\n",
    "columns = ['word_freq_make', 'word_freq_address', 'word_freq_all', 'word_freq_3d', 'word_freq_our', 'word_freq_over', 'word_freq_remove', 'word_freq_internet', 'word_freq_order', 'word_freq_mail', 'word_freq_receive', 'word_freq_will', 'word_freq_people', 'word_freq_report', 'word_freq_addresses', 'word_freq_free', 'word_freq_business', 'word_freq_email', 'word_freq_you', 'word_freq_credit', 'word_freq_your', 'word_freq_font', 'word_freq_000', 'word_freq_money', 'word_freq_hp', 'word_freq_hpl', 'word_freq_george', 'word_freq_650', 'word_freq_lab', 'word_freq_labs', 'word_freq_telnet', 'word_freq_857', 'word_freq_data', 'word_freq_415', 'word_freq_85', 'word_freq_technology', 'word_freq_1999', 'word_freq_parts', 'word_freq_pm', 'word_freq_direct', 'word_freq_cs', 'word_freq_meeting', 'word_freq_original', 'word_freq_project', 'word_freq_re', 'word_freq_edu', 'word_freq_table', 'word_freq_conference', 'charfreq;', 'charfreq(', 'charfreq[', 'charfreq!', 'charfreq$', 'charfreq#', 'capital_run_length_average', 'capital_run_length_longest', 'capital_run_length_total', 'spam/nonspam']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Data\n",
    "data = pd.read_csv(file_path, header=None, names=columns, sep=\",\")\n",
    "\n",
    "# check if null\n",
    "data.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:, :-1]  # Features\n",
    "y = data.iloc[:, -1]   # Target variable\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define 10-fold stratified cross-validation\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75.5 ms ± 509 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "Decision Tree Accuracy: 0.9185667752442996\n",
      "Decision Tree F-Measure: 0.9019607843137256\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree\n",
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "%timeit dt_model.fit(X_train, y_train)\n",
    "dt_predictions = dt_model.predict(X_test)\n",
    "dt_accuracy = accuracy_score(y_test, dt_predictions)\n",
    "dt_f_measure = f1_score(y_test, dt_predictions, average='binary')\n",
    "print(f'Decision Tree Accuracy: {dt_accuracy}')\n",
    "print(f'Decision Tree F-Measure: {dt_f_measure}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.63 ms ± 240 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "KNN Accuracy: 0.7904451682953312\n",
      "Random Forest F-Measure: 0.7423230974632844\n"
     ]
    }
   ],
   "source": [
    "# k-Nearest Neighbors (KNN)\n",
    "knn_model = KNeighborsClassifier()\n",
    "\n",
    "%timeit knn_model.fit(X_train, y_train)\n",
    "knn_predictions = knn_model.predict(X_test)\n",
    "knn_accuracy = accuracy_score(y_test, knn_predictions)\n",
    "knn_f_measure = f1_score(y_test, knn_predictions)\n",
    "print(f'KNN Accuracy: {knn_accuracy}')\n",
    "print(f'Random Forest F-Measure: {knn_f_measure}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "838 ms ± 10.2 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "Random Forest Accuracy: 0.9554831704668838\n",
      "Random Forest F-Measure: 0.9458388375165125\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "%timeit rf_model.fit(X_train, y_train)\n",
    "rf_predictions = rf_model.predict(X_test)\n",
    "rf_accuracy = accuracy_score(y_test, rf_predictions)\n",
    "rf_f_measure = f1_score(y_test, rf_predictions, average='binary')\n",
    "print(f'Random Forest Accuracy: {rf_accuracy}')\n",
    "print(f'Random Forest F-Measure: {rf_f_measure}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Decision Tree  k-Nearest Neighbors  Random Forest\n",
      "1           0.910679         8.096081e-01   9.547930e-01\n",
      "2           0.910679         8.096081e-01   9.547930e-01\n",
      "3           0.910679         8.096081e-01   9.547930e-01\n",
      "4           0.910679         8.096081e-01   9.547930e-01\n",
      "5           0.910679         8.096081e-01   9.547930e-01\n",
      "6           0.910679         8.096081e-01   9.547930e-01\n",
      "7           0.910679         8.096081e-01   9.547930e-01\n",
      "8           0.910679         8.096081e-01   9.547930e-01\n",
      "9           0.910679         8.096081e-01   9.547930e-01\n",
      "10          0.910679         8.096081e-01   9.547930e-01\n",
      "avg         0.910679         8.096081e-01   9.547930e-01\n",
      "stdev       0.000000         1.164412e-16   2.248030e-16\n",
      "Average Ranks:\n",
      "[2. 1. 3.]\n"
     ]
    }
   ],
   "source": [
    "# Initialize an empty DataFrame to store results\n",
    "results_df = pd.DataFrame(index=range(1, 11))\n",
    "\n",
    "# Loop through each fold\n",
    "for fold in range(1, 11):\n",
    "    # Decision Tree\n",
    "    dt_scores = cross_val_score(dt_model, X, y, cv=cv, scoring='accuracy')\n",
    "    results_df.at[fold, 'Decision Tree'] = dt_scores.mean()\n",
    "    \n",
    "    # KNN\n",
    "    knn_scores = cross_val_score(knn_model, X, y, cv=cv, scoring='accuracy')\n",
    "    results_df.at[fold, 'k-Nearest Neighbors'] = knn_scores.mean()\n",
    "\n",
    "    # Random Forest\n",
    "    rf_scores = cross_val_score(rf_model, X, y, cv=cv, scoring='accuracy')\n",
    "    results_df.at[fold, 'Random Forest'] = rf_scores.mean()\n",
    "\n",
    "# Calculate average and standard deviation\n",
    "results_df.at['avg', :] = results_df.mean(axis=0)\n",
    "results_df.at['stdev', :] = results_df.std(axis=0)\n",
    "\n",
    "# Display the results\n",
    "print(results_df)\n",
    "\n",
    "# Calculate average ranks\n",
    "average_ranks = rankdata(results_df.iloc[:-2, :].values, axis=1).mean(axis=0)\n",
    "\n",
    "# Display the average ranks\n",
    "print(\"Average Ranks:\")\n",
    "print(average_ranks)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Friedman test p-value: 1.5366306526875732e-05\n",
      "Critical Difference: 3.7907484397561317\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Conduct the Friedman test\n",
    "_, p_value = friedmanchisquare(\n",
    "    results_df['Decision Tree'], \n",
    "    results_df['k-Nearest Neighbors'], \n",
    "    results_df['Random Forest']\n",
    ")\n",
    "print(f'Friedman test p-value: {p_value}')\n",
    "\n",
    "# If p-value is significant, proceed with Nemenyi test\n",
    "if p_value < 0.05:\n",
    "    # Function to calculate the critical difference using Nemenyi test\n",
    "    def nemenyi_critical_difference(rank_avg, num_algorithms, num_samples):\n",
    "        q_val = chi2.ppf(1 - 0.05 / (2 * num_algorithms * (num_algorithms - 1)) ** 0.5, df=num_algorithms - 1)\n",
    "        return q_val * (num_algorithms * (num_algorithms + 1) / (6 * num_samples)) ** 0.5\n",
    "\n",
    "    # Rank the algorithms\n",
    "    ranks = rankdata(results_df.iloc[:-2, :].values, axis=1).mean(axis=0)\n",
    "\n",
    "    # Calculate critical difference\n",
    "    num_algorithms = results_df.shape[1]\n",
    "    num_samples = results_df.shape[0] - 2\n",
    "    cd = nemenyi_critical_difference(ranks, num_algorithms, num_samples)\n",
    "    print(f'Critical Difference: {cd}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average ranks do not display significant differences.\n"
     ]
    }
   ],
   "source": [
    "# Calculate average ranks\n",
    "average_ranks = rankdata(results_df.iloc[:-2, :].values, axis=1).mean(axis=0)\n",
    "\n",
    "# Calculate rank sums for each algorithm\n",
    "rank_sums = [np.sum(ranks) for ranks in results_df.iloc[:-2, :].values]\n",
    "\n",
    "# Calculate H-statistic for the Kruskal-Wallis test\n",
    "H_statistic, _ = kruskal(*results_df.iloc[:-2, :].values)\n",
    "\n",
    "# Calculate critical value for the Kruskal-Wallis test\n",
    "k = results_df.shape[1]  # Number of algorithms\n",
    "n = results_df.shape[0] - 2  # Number of samples (folds)\n",
    "critical_value = 3.841  # From the chi-squared distribution table for alpha = 0.05 and df = k - 1\n",
    "\n",
    "# Determine whether the average ranks display significant differences\n",
    "if H_statistic > critical_value:\n",
    "    print(\"The average ranks display significant differences.\")\n",
    "\n",
    "    # Use Nemenyi test to calculate critical difference\n",
    "    cd_nemenyi = nemenyi_critical_difference(average_ranks, k, n)\n",
    "    print(f'Critical Difference (Nemenyi): {cd_nemenyi}')\n",
    "\n",
    "    # Identify which algorithms perform significantly differently from each other\n",
    "    significant_pairs = []\n",
    "    for i in range(k - 1):\n",
    "        for j in range(i + 1, k):\n",
    "            diff = np.abs(average_ranks[i] - average_ranks[j])\n",
    "            if diff > cd_nemenyi:\n",
    "                significant_pairs.append((i, j))\n",
    "\n",
    "    print(\"Significantly different algorithm pairs:\")\n",
    "    for pair in significant_pairs:\n",
    "        algorithm1, algorithm2 = pair\n",
    "        print(f\"{results_df.columns[algorithm1]} and {results_df.columns[algorithm2]}\")\n",
    "\n",
    "else:\n",
    "    print(\"The average ranks do not display significant differences.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Average Rank\n",
      "Decision Tree                NaN\n",
      "k-Nearest Neighbors          NaN\n",
      "Random Forest                NaN\n"
     ]
    }
   ],
   "source": [
    "# Extracting the algorithm names\n",
    "algorithm_names = ['Decision Tree', 'k-Nearest Neighbors', 'Random Forest']\n",
    "\n",
    "# Creating a DataFrame to store average ranks\n",
    "avg_ranks_df = pd.DataFrame(index=algorithm_names, columns=['Average Rank'])\n",
    "\n",
    "\n",
    "# Displaying the average ranks\n",
    "print(avg_ranks_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import pandas as pd\\nfrom scipy.stats import rankdata\\nfrom sklearn.model_selection import cross_val_score, KFold\\n\\n# Initialize an empty DataFrame to store results\\nresults_df = pd.DataFrame(index=range(1, 11))\\n\\n# Initialize models outside the loop\\ndt_model = decision_tree_model  # Replace with your actual model\\nknn_model = knn_model  # Replace with your actual model\\nrf_model = random_forest_model  # Replace with your actual model\\n\\n# Loop through each fold\\ncv = KFold(n_splits=10, shuffle=True, random_state=42)  # Adjust the parameters as needed\\nfor fold, (train_idx, test_idx) in enumerate(cv.split(X), start=1):\\n    # Decision Tree\\n    dt_scores = cross_val_score(dt_model, X.iloc[train_idx], y.iloc[train_idx], cv=cv, scoring=\\'accuracy\\')\\n    results_df.at[fold, \\'Decision Tree\\'] = dt_scores.mean()\\n    \\n    # KNN\\n    knn_scores = cross_val_score(knn_model, X.iloc[train_idx], y.iloc[train_idx], cv=cv, scoring=\\'accuracy\\')\\n    results_df.at[fold, \\'k-Nearest Neighbors\\'] = knn_scores.mean()\\n\\n    # Random Forest\\n    rf_scores = cross_val_score(rf_model, X.iloc[train_idx], y.iloc[train_idx], cv=cv, scoring=\\'accuracy\\')\\n    results_df.at[fold, \\'Random Forest\\'] = rf_scores.mean()\\n\\n# Calculate average and standard deviation\\nresults_df.at[\\'avg\\', :] = results_df.mean(axis=0)\\nresults_df.at[\\'stdev\\', :] = results_df.std(axis=0)\\n\\n# Calculate ranks\\nranks_df = results_df.rank(ascending=False, method=\\'average\\')\\n\\n# Display the results with ranks and standard deviations\\nfor algorithm in results_df.columns:\\n    print(f\"{algorithm} Scores, Ranks, and Stdev:\")\\n    for fold in range(1, 11):\\n        score = results_df.at[fold, algorithm]\\n        rank = ranks_df.at[fold, algorithm]\\n        stdev = results_df.at[fold, algorithm]\\n        print(f\"Fold {fold}: {score:.4f} (Rank {int(rank)}) - Stdev: {stdev:.4f}\")\\n    avg_score = results_df.at[\\'avg\\', algorithm]\\n    avg_rank = ranks_df.at[\\'avg\\', algorithm]\\n    avg_stdev = results_df.at[\\'stdev\\', algorithm]\\n    print(f\"Avg: {avg_score:.4f} (Avg Rank {int(avg_rank)}) - Avg Stdev: {avg_stdev:.4f}\\n\")\\n\\nprint(results_df)\\nprint(ranks_df)\\n\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"import pandas as pd\n",
    "from scipy.stats import rankdata\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "\n",
    "# Initialize an empty DataFrame to store results\n",
    "results_df = pd.DataFrame(index=range(1, 11))\n",
    "\n",
    "# Initialize models outside the loop\n",
    "dt_model = decision_tree_model  # Replace with your actual model\n",
    "knn_model = knn_model  # Replace with your actual model\n",
    "rf_model = random_forest_model  # Replace with your actual model\n",
    "\n",
    "# Loop through each fold\n",
    "cv = KFold(n_splits=10, shuffle=True, random_state=42)  # Adjust the parameters as needed\n",
    "for fold, (train_idx, test_idx) in enumerate(cv.split(X), start=1):\n",
    "    # Decision Tree\n",
    "    dt_scores = cross_val_score(dt_model, X.iloc[train_idx], y.iloc[train_idx], cv=cv, scoring='accuracy')\n",
    "    results_df.at[fold, 'Decision Tree'] = dt_scores.mean()\n",
    "    \n",
    "    # KNN\n",
    "    knn_scores = cross_val_score(knn_model, X.iloc[train_idx], y.iloc[train_idx], cv=cv, scoring='accuracy')\n",
    "    results_df.at[fold, 'k-Nearest Neighbors'] = knn_scores.mean()\n",
    "\n",
    "    # Random Forest\n",
    "    rf_scores = cross_val_score(rf_model, X.iloc[train_idx], y.iloc[train_idx], cv=cv, scoring='accuracy')\n",
    "    results_df.at[fold, 'Random Forest'] = rf_scores.mean()\n",
    "\n",
    "# Calculate average and standard deviation\n",
    "results_df.at['avg', :] = results_df.mean(axis=0)\n",
    "results_df.at['stdev', :] = results_df.std(axis=0)\n",
    "\n",
    "# Calculate ranks\n",
    "ranks_df = results_df.rank(ascending=False, method='average')\n",
    "\n",
    "# Display the results with ranks and standard deviations\n",
    "for algorithm in results_df.columns:\n",
    "    print(f\"{algorithm} Scores, Ranks, and Stdev:\")\n",
    "    for fold in range(1, 11):\n",
    "        score = results_df.at[fold, algorithm]\n",
    "        rank = ranks_df.at[fold, algorithm]\n",
    "        stdev = results_df.at[fold, algorithm]\n",
    "        print(f\"Fold {fold}: {score:.4f} (Rank {int(rank)}) - Stdev: {stdev:.4f}\")\n",
    "    avg_score = results_df.at['avg', algorithm]\n",
    "    avg_rank = ranks_df.at['avg', algorithm]\n",
    "    avg_stdev = results_df.at['stdev', algorithm]\n",
    "    print(f\"Avg: {avg_score:.4f} (Avg Rank {int(avg_rank)}) - Avg Stdev: {avg_stdev:.4f}\\n\")\n",
    "\n",
    "print(results_df)\n",
    "print(ranks_df)\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Scores, Ranks, and Stdev:\n",
      "Fold 1: 0.9210 (Rank 1) - Stdev: 0.9210\n",
      "Fold 2: 0.9077 (Rank 1) - Stdev: 0.9077\n",
      "Fold 3: 0.9131 (Rank 1) - Stdev: 0.9131\n",
      "Fold 4: 0.9150 (Rank 1) - Stdev: 0.9150\n",
      "Fold 5: 0.9150 (Rank 1) - Stdev: 0.9150\n",
      "Fold 6: 0.9167 (Rank 1) - Stdev: 0.9167\n",
      "Fold 7: 0.9184 (Rank 1) - Stdev: 0.9184\n",
      "Fold 8: 0.9157 (Rank 1) - Stdev: 0.9157\n",
      "Fold 9: 0.9162 (Rank 1) - Stdev: 0.9162\n",
      "Fold 10: 0.9046 (Rank 1) - Stdev: 0.9046\n",
      "Avg: 0.9143 (Avg Rank 1) - Avg Stdev: 0.0046\n",
      "\n",
      "k-Nearest Neighbors Scores, Ranks, and Stdev:\n",
      "Fold 1: 0.8121 (Rank 1) - Stdev: 0.8121\n",
      "Fold 2: 0.8039 (Rank 1) - Stdev: 0.8039\n",
      "Fold 3: 0.8075 (Rank 1) - Stdev: 0.8075\n",
      "Fold 4: 0.8032 (Rank 1) - Stdev: 0.8032\n",
      "Fold 5: 0.8010 (Rank 1) - Stdev: 0.8010\n",
      "Fold 6: 0.8037 (Rank 1) - Stdev: 0.8037\n",
      "Fold 7: 0.8008 (Rank 1) - Stdev: 0.8008\n",
      "Fold 8: 0.7974 (Rank 1) - Stdev: 0.7974\n",
      "Fold 9: 0.8001 (Rank 1) - Stdev: 0.8001\n",
      "Fold 10: 0.8044 (Rank 1) - Stdev: 0.8044\n",
      "Avg: 0.8034 (Avg Rank 1) - Avg Stdev: 0.0039\n",
      "\n",
      "Random Forest Scores, Ranks, and Stdev:\n",
      "Fold 1: 0.9522 (Rank 1) - Stdev: 0.9522\n",
      "Fold 2: 0.9519 (Rank 1) - Stdev: 0.9519\n",
      "Fold 3: 0.9534 (Rank 1) - Stdev: 0.9534\n",
      "Fold 4: 0.9556 (Rank 1) - Stdev: 0.9556\n",
      "Fold 5: 0.9527 (Rank 1) - Stdev: 0.9527\n",
      "Fold 6: 0.9539 (Rank 1) - Stdev: 0.9539\n",
      "Fold 7: 0.9553 (Rank 1) - Stdev: 0.9553\n",
      "Fold 8: 0.9495 (Rank 1) - Stdev: 0.9495\n",
      "Fold 9: 0.9551 (Rank 1) - Stdev: 0.9551\n",
      "Fold 10: 0.9493 (Rank 1) - Stdev: 0.9493\n",
      "Avg: 0.9529 (Avg Rank 1) - Avg Stdev: 0.0021\n",
      "\n",
      "       Decision Tree  k-Nearest Neighbors  Random Forest\n",
      "1           0.921014             0.812077       0.952174\n",
      "2           0.907750             0.803919       0.951942\n",
      "3           0.913065             0.807536       0.953396\n",
      "4           0.914992             0.803186       0.955565\n",
      "5           0.914997             0.801012       0.952669\n",
      "6           0.916687             0.803669       0.953879\n",
      "7           0.918377             0.800770       0.955326\n",
      "8           0.915719             0.797393       0.949525\n",
      "9           0.916199             0.800056       0.955084\n",
      "10          0.904607             0.804391       0.949285\n",
      "avg         0.914341             0.803401       0.952885\n",
      "stdev       0.004608             0.003920       0.002119\n"
     ]
    }
   ],
   "source": [
    "# Initialize an empty DataFrame to store results\n",
    "results_df = pd.DataFrame(index=range(1, 11))\n",
    "\n",
    "# Loop through each fold\n",
    "cv = KFold(n_splits=10, shuffle=True, random_state=42)  # Adjust the parameters as needed\n",
    "for fold, (train_idx, test_idx) in enumerate(cv.split(X), start=1):\n",
    "    # Decision Tree\n",
    "    dt_scores = cross_val_score(dt_model, X.iloc[train_idx], y.iloc[train_idx], cv=cv, scoring='accuracy')\n",
    "    results_df.at[fold, 'Decision Tree'] = dt_scores.mean()\n",
    "    \n",
    "    # KNN\n",
    "    knn_scores = cross_val_score(knn_model, X.iloc[train_idx], y.iloc[train_idx], cv=cv, scoring='accuracy')\n",
    "    results_df.at[fold, 'k-Nearest Neighbors'] = knn_scores.mean()\n",
    "\n",
    "    # Random Forest\n",
    "    rf_scores = cross_val_score(rf_model, X.iloc[train_idx], y.iloc[train_idx], cv=cv, scoring='accuracy')\n",
    "    results_df.at[fold, 'Random Forest'] = rf_scores.mean()\n",
    "\n",
    "# Calculate average and standard deviation\n",
    "results_df.loc['avg', :] = results_df.mean(axis=0)\n",
    "results_df.loc['stdev', :] = results_df.std(axis=0)\n",
    "\n",
    "# Calculate ranks\n",
    "ranks_df = results_df.rank(ascending=False, method='average')\n",
    "\n",
    "# Display the results with ranks and standard deviations\n",
    "for algorithm in results_df.columns:\n",
    "    print(f\"{algorithm} Scores, Ranks, and Stdev:\")\n",
    "    for fold in range(1, 11):\n",
    "        score = results_df.at[fold, algorithm]\n",
    "        rank = rankdata(results_df.loc[fold, algorithm])\n",
    "        stdev = results_df.at[fold, algorithm]\n",
    "        print(f\"Fold {fold}: {score:.4f} (Rank {int(rank)}) - Stdev: {stdev:.4f}\")\n",
    "    avg_score = results_df.at['avg', algorithm]\n",
    "    avg_rank = rankdata(results_df.loc['avg', algorithm])[0]\n",
    "    avg_stdev = results_df.at['stdev', algorithm]\n",
    "    print(f\"Avg: {avg_score:.4f} (Avg Rank {int(avg_rank)}) - Avg Stdev: {avg_stdev:.4f}\\n\")\n",
    "\n",
    "print(results_df)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
