{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Assigment 2\n",
    "Spambase, Anna Bergknut, DVAMI21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as mpl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as scp\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold, train_test_split\n",
    "\n",
    "from scipy.stats import friedmanchisquare, rankdata, norm, chi2, ranksums, kruskal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"spambase.data\"\n",
    "columns = ['word_freq_make', 'word_freq_address', 'word_freq_all', 'word_freq_3d', 'word_freq_our', 'word_freq_over', 'word_freq_remove', 'word_freq_internet', 'word_freq_order', 'word_freq_mail', 'word_freq_receive', 'word_freq_will', 'word_freq_people', 'word_freq_report', 'word_freq_addresses', 'word_freq_free', 'word_freq_business', 'word_freq_email', 'word_freq_you', 'word_freq_credit', 'word_freq_your', 'word_freq_font', 'word_freq_000', 'word_freq_money', 'word_freq_hp', 'word_freq_hpl', 'word_freq_george', 'word_freq_650', 'word_freq_lab', 'word_freq_labs', 'word_freq_telnet', 'word_freq_857', 'word_freq_data', 'word_freq_415', 'word_freq_85', 'word_freq_technology', 'word_freq_1999', 'word_freq_parts', 'word_freq_pm', 'word_freq_direct', 'word_freq_cs', 'word_freq_meeting', 'word_freq_original', 'word_freq_project', 'word_freq_re', 'word_freq_edu', 'word_freq_table', 'word_freq_conference', 'charfreq;', 'charfreq(', 'charfreq[', 'charfreq!', 'charfreq$', 'charfreq#', 'capital_run_length_average', 'capital_run_length_longest', 'capital_run_length_total', 'spam/nonspam']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Data\n",
    "data = pd.read_csv(file_path, header=None, names=columns, sep=\",\")\n",
    "\n",
    "# check if null\n",
    "data.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:, :-1]  # Features\n",
    "y = data.iloc[:, -1]   # Target variable\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define 10-fold stratified cross-validation\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75.6 ms ± 982 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "Decision Tree Accuracy: 0.9185667752442996\n",
      "Decision Tree F-Measure: 0.9019607843137256\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree\n",
    "decision_tree_model = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "%timeit decision_tree_model.fit(X_train, y_train)\n",
    "dt_predictions = decision_tree_model.predict(X_test)\n",
    "dt_accuracy = accuracy_score(y_test, dt_predictions)\n",
    "dt_f_measure = f1_score(y_test, dt_predictions, average='binary')\n",
    "print(f'Decision Tree Accuracy: {dt_accuracy}')\n",
    "print(f'Decision Tree F-Measure: {dt_f_measure}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.78 ms ± 145 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "KNN Accuracy: 0.7904451682953312\n",
      "Random Forest F-Measure: 0.7423230974632844\n"
     ]
    }
   ],
   "source": [
    "# k-Nearest Neighbors (KNN)\n",
    "knn_model = KNeighborsClassifier()\n",
    "\n",
    "%timeit knn_model.fit(X_train, y_train)\n",
    "knn_predictions = knn_model.predict(X_test)\n",
    "knn_accuracy = accuracy_score(y_test, knn_predictions)\n",
    "knn_f_measure = f1_score(y_test, knn_predictions)\n",
    "print(f'KNN Accuracy: {knn_accuracy}')\n",
    "print(f'Random Forest F-Measure: {knn_f_measure}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "836 ms ± 23.1 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "Random Forest Accuracy: 0.9554831704668838\n",
      "Random Forest F-Measure: 0.9458388375165125\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "random_forest_model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "%timeit random_forest_model.fit(X_train, y_train)\n",
    "rf_predictions = random_forest_model.predict(X_test)\n",
    "rf_accuracy = accuracy_score(y_test, rf_predictions)\n",
    "rf_f_measure = f1_score(y_test, rf_predictions, average='binary')\n",
    "print(f'Random Forest Accuracy: {rf_accuracy}')\n",
    "print(f'Random Forest F-Measure: {rf_f_measure}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Decision Tree  k-Nearest Neighbors  Random Forest\n",
      "1           0.910679         8.096081e-01   9.547930e-01\n",
      "2           0.910679         8.096081e-01   9.547930e-01\n",
      "3           0.910679         8.096081e-01   9.547930e-01\n",
      "4           0.910679         8.096081e-01   9.547930e-01\n",
      "5           0.910679         8.096081e-01   9.547930e-01\n",
      "6           0.910679         8.096081e-01   9.547930e-01\n",
      "7           0.910679         8.096081e-01   9.547930e-01\n",
      "8           0.910679         8.096081e-01   9.547930e-01\n",
      "9           0.910679         8.096081e-01   9.547930e-01\n",
      "10          0.910679         8.096081e-01   9.547930e-01\n",
      "avg         0.910679         8.096081e-01   9.547930e-01\n",
      "stdev       0.000000         1.164412e-16   2.248030e-16\n"
     ]
    }
   ],
   "source": [
    "# Initialize an empty DataFrame to store results\n",
    "results_df = pd.DataFrame(index=range(1, 11))\n",
    "\n",
    "# Loop through each fold\n",
    "for fold in range(1, 11):\n",
    "    # Decision Tree\n",
    "    dt_scores = cross_val_score(decision_tree_model, X, y, cv=cv, scoring='accuracy')\n",
    "    results_df.at[fold, 'Decision Tree'] = dt_scores.mean()\n",
    "    \n",
    "    # KNN\n",
    "    knn_scores = cross_val_score(knn_model, X, y, cv=cv, scoring='accuracy')\n",
    "    results_df.at[fold, 'k-Nearest Neighbors'] = knn_scores.mean()\n",
    "\n",
    "    # Random Forest\n",
    "    rf_scores = cross_val_score(random_forest_model, X, y, cv=cv, scoring='accuracy')\n",
    "    results_df.at[fold, 'Random Forest'] = rf_scores.mean()\n",
    "\n",
    "# Calculate average and standard deviation\n",
    "results_df.at['avg', :] = results_df.mean(axis=0)\n",
    "results_df.at['stdev', :] = results_df.std(axis=0)\n",
    "\n",
    "# Display the results\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Friedman test p-value: 1.5366306526875732e-05\n",
      "Critical Difference: 3.7907484397561317\n"
     ]
    }
   ],
   "source": [
    "# Conduct the Friedman test\n",
    "_, p_value = friedmanchisquare(\n",
    "    results_df['Decision Tree'], \n",
    "    results_df['k-Nearest Neighbors'],  # Corrected column name\n",
    "    results_df['Random Forest']\n",
    ")\n",
    "print(f'Friedman test p-value: {p_value}')\n",
    "\n",
    "# If p-value is significant, proceed with Nemenyi test\n",
    "if p_value < 0.05:\n",
    "    # Function to calculate the critical difference using Nemenyi test\n",
    "    def nemenyi_critical_difference(rank_avg, num_algorithms, num_samples):\n",
    "        q_val = chi2.ppf(1 - 0.05 / (2 * num_algorithms * (num_algorithms - 1)) ** 0.5, df=num_algorithms - 1)\n",
    "        return q_val * (num_algorithms * (num_algorithms + 1) / (6 * num_samples)) ** 0.5\n",
    "\n",
    "    # Rank the algorithms\n",
    "    ranks = rankdata(results_df.iloc[:-2, :].values, axis=1).mean(axis=0)\n",
    "\n",
    "    # Calculate critical difference\n",
    "    num_algorithms = results_df.shape[1]\n",
    "    num_samples = results_df.shape[0] - 2\n",
    "    cd = nemenyi_critical_difference(ranks, num_algorithms, num_samples)\n",
    "    print(f'Critical Difference: {cd}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average ranks do not display significant differences.\n"
     ]
    }
   ],
   "source": [
    "# Calculate average ranks\n",
    "average_ranks = rankdata(results_df.iloc[:-2, :].values, axis=1).mean(axis=0)\n",
    "\n",
    "# Calculate rank sums for each algorithm\n",
    "rank_sums = [np.sum(ranks) for ranks in results_df.iloc[:-2, :].values]\n",
    "\n",
    "# Calculate H-statistic for the Kruskal-Wallis test\n",
    "H_statistic, _ = kruskal(*results_df.iloc[:-2, :].values)\n",
    "\n",
    "# Calculate critical value for the Kruskal-Wallis test\n",
    "k = results_df.shape[1]  # Number of algorithms\n",
    "n = results_df.shape[0] - 2  # Number of samples (folds)\n",
    "critical_value = 3.841  # From the chi-squared distribution table for alpha = 0.05 and df = k - 1\n",
    "\n",
    "# Determine whether the average ranks display significant differences\n",
    "if H_statistic > critical_value:\n",
    "    print(\"The average ranks display significant differences.\")\n",
    "\n",
    "    # Use Nemenyi test to calculate critical difference\n",
    "    cd_nemenyi = nemenyi_critical_difference(average_ranks, k, n)\n",
    "    print(f'Critical Difference (Nemenyi): {cd_nemenyi}')\n",
    "\n",
    "    # Identify which algorithms perform significantly differently from each other\n",
    "    significant_pairs = []\n",
    "    for i in range(k - 1):\n",
    "        for j in range(i + 1, k):\n",
    "            diff = np.abs(average_ranks[i] - average_ranks[j])\n",
    "            if diff > cd_nemenyi:\n",
    "                significant_pairs.append((i, j))\n",
    "\n",
    "    print(\"Significantly different algorithm pairs:\")\n",
    "    for pair in significant_pairs:\n",
    "        algorithm1, algorithm2 = pair\n",
    "        print(f\"{results_df.columns[algorithm1]} and {results_df.columns[algorithm2]}\")\n",
    "\n",
    "else:\n",
    "    print(\"The average ranks do not display significant differences.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
