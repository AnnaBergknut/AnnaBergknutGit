{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Assigment 2\n",
    "Spambase, Anna Bergknut, DVAMI21\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold, train_test_split\n",
    "\n",
    "from scipy.stats import friedmanchisquare, rankdata, chi2, kruskal\n",
    "from sklearn.model_selection import cross_val_score, KFold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"spambase.data\"\n",
    "columns = ['word_freq_make', 'word_freq_address', 'word_freq_all', 'word_freq_3d', 'word_freq_our', 'word_freq_over', 'word_freq_remove', 'word_freq_internet', 'word_freq_order', 'word_freq_mail', 'word_freq_receive', 'word_freq_will', 'word_freq_people', 'word_freq_report', 'word_freq_addresses', 'word_freq_free', 'word_freq_business', 'word_freq_email', 'word_freq_you', 'word_freq_credit', 'word_freq_your', 'word_freq_font', 'word_freq_000', 'word_freq_money', 'word_freq_hp', 'word_freq_hpl', 'word_freq_george', 'word_freq_650', 'word_freq_lab', 'word_freq_labs', 'word_freq_telnet', 'word_freq_857', 'word_freq_data', 'word_freq_415', 'word_freq_85', 'word_freq_technology', 'word_freq_1999', 'word_freq_parts', 'word_freq_pm', 'word_freq_direct', 'word_freq_cs', 'word_freq_meeting', 'word_freq_original', 'word_freq_project', 'word_freq_re', 'word_freq_edu', 'word_freq_table', 'word_freq_conference', 'charfreq;', 'charfreq(', 'charfreq[', 'charfreq!', 'charfreq$', 'charfreq#', 'capital_run_length_average', 'capital_run_length_longest', 'capital_run_length_total', 'spam/nonspam']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Data\n",
    "data = pd.read_csv(file_path, header=None, names=columns, sep=\",\")\n",
    "\n",
    "# check if null\n",
    "data.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:, :-1]  # Features\n",
    "y = data.iloc[:, -1]   # Target variable\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define 10-fold stratified cross-validation\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75.6 ms ± 976 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "Decision Tree Accuracy: 0.9185667752442996\n",
      "Decision Tree F-Measure: 0.9019607843137256\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree\n",
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "%timeit dt_model.fit(X_train, y_train)\n",
    "dt_predictions = dt_model.predict(X_test)\n",
    "dt_accuracy = accuracy_score(y_test, dt_predictions)\n",
    "dt_f_measure = f1_score(y_test, dt_predictions, average='binary')\n",
    "print(f'Decision Tree Accuracy: {dt_accuracy}')\n",
    "print(f'Decision Tree F-Measure: {dt_f_measure}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.3 ms ± 101 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "KNN Accuracy: 0.7904451682953312\n",
      "Random Forest F-Measure: 0.7423230974632844\n"
     ]
    }
   ],
   "source": [
    "# k-Nearest Neighbors (KNN)\n",
    "knn_model = KNeighborsClassifier()\n",
    "\n",
    "%timeit knn_model.fit(X_train, y_train)\n",
    "knn_predictions = knn_model.predict(X_test)\n",
    "knn_accuracy = accuracy_score(y_test, knn_predictions)\n",
    "knn_f_measure = f1_score(y_test, knn_predictions)\n",
    "print(f'KNN Accuracy: {knn_accuracy}')\n",
    "print(f'Random Forest F-Measure: {knn_f_measure}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "853 ms ± 32.2 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "Random Forest Accuracy: 0.9554831704668838\n",
      "Random Forest F-Measure: 0.9458388375165125\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "%timeit rf_model.fit(X_train, y_train)\n",
    "rf_predictions = rf_model.predict(X_test)\n",
    "rf_accuracy = accuracy_score(y_test, rf_predictions)\n",
    "rf_f_measure = f1_score(y_test, rf_predictions, average='binary')\n",
    "print(f'Random Forest Accuracy: {rf_accuracy}')\n",
    "print(f'Random Forest F-Measure: {rf_f_measure}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Decision Tree  k-Nearest Neighbors  Random Forest\n",
      "1           0.910679         8.096081e-01   9.547930e-01\n",
      "2           0.910679         8.096081e-01   9.547930e-01\n",
      "3           0.910679         8.096081e-01   9.547930e-01\n",
      "4           0.910679         8.096081e-01   9.547930e-01\n",
      "5           0.910679         8.096081e-01   9.547930e-01\n",
      "6           0.910679         8.096081e-01   9.547930e-01\n",
      "7           0.910679         8.096081e-01   9.547930e-01\n",
      "8           0.910679         8.096081e-01   9.547930e-01\n",
      "9           0.910679         8.096081e-01   9.547930e-01\n",
      "10          0.910679         8.096081e-01   9.547930e-01\n",
      "avg         0.910679         8.096081e-01   9.547930e-01\n",
      "stdev       0.000000         1.164412e-16   2.248030e-16\n",
      "Average Ranks:\n",
      "[2. 1. 3.]\n"
     ]
    }
   ],
   "source": [
    "# Initialize an empty DataFrame to store results\n",
    "results_df = pd.DataFrame(index=range(1, 11))\n",
    "\n",
    "# Loop through each fold\n",
    "for fold in range(1, 11):\n",
    "    # Decision Tree\n",
    "    dt_scores = cross_val_score(dt_model, X, y, cv=cv, scoring='accuracy')\n",
    "    results_df.at[fold, 'Decision Tree'] = dt_scores.mean()\n",
    "    \n",
    "    # KNN\n",
    "    knn_scores = cross_val_score(knn_model, X, y, cv=cv, scoring='accuracy')\n",
    "    results_df.at[fold, 'k-Nearest Neighbors'] = knn_scores.mean()\n",
    "\n",
    "    # Random Forest\n",
    "    rf_scores = cross_val_score(rf_model, X, y, cv=cv, scoring='accuracy')\n",
    "    results_df.at[fold, 'Random Forest'] = rf_scores.mean()\n",
    "\n",
    "# Calculate average and standard deviation\n",
    "results_df.at['avg', :] = results_df.mean(axis=0)\n",
    "results_df.at['stdev', :] = results_df.std(axis=0)\n",
    "\n",
    "# Display the results\n",
    "print(results_df)\n",
    "\n",
    "# Calculate average ranks\n",
    "average_ranks = rankdata(results_df.iloc[:-2, :].values, axis=1).mean(axis=0)\n",
    "\n",
    "# Display the average ranks\n",
    "print(\"Average Ranks:\")\n",
    "print(average_ranks)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Scores, Ranks, and Stdev:\n",
      "Fold 1: 0.9210 (Rank 1) - Stdev: 0.9210\n",
      "Fold 2: 0.9077 (Rank 1) - Stdev: 0.9077\n",
      "Fold 3: 0.9131 (Rank 1) - Stdev: 0.9131\n",
      "Fold 4: 0.9150 (Rank 1) - Stdev: 0.9150\n",
      "Fold 5: 0.9150 (Rank 1) - Stdev: 0.9150\n",
      "Fold 6: 0.9167 (Rank 1) - Stdev: 0.9167\n",
      "Fold 7: 0.9184 (Rank 1) - Stdev: 0.9184\n",
      "Fold 8: 0.9157 (Rank 1) - Stdev: 0.9157\n",
      "Fold 9: 0.9162 (Rank 1) - Stdev: 0.9162\n",
      "Fold 10: 0.9046 (Rank 1) - Stdev: 0.9046\n",
      "Avg: 0.9143 (Avg Rank 1) - Avg Stdev: 0.0046\n",
      "\n",
      "k-Nearest Neighbors Scores, Ranks, and Stdev:\n",
      "Fold 1: 0.8121 (Rank 1) - Stdev: 0.8121\n",
      "Fold 2: 0.8039 (Rank 1) - Stdev: 0.8039\n",
      "Fold 3: 0.8075 (Rank 1) - Stdev: 0.8075\n",
      "Fold 4: 0.8032 (Rank 1) - Stdev: 0.8032\n",
      "Fold 5: 0.8010 (Rank 1) - Stdev: 0.8010\n",
      "Fold 6: 0.8037 (Rank 1) - Stdev: 0.8037\n",
      "Fold 7: 0.8008 (Rank 1) - Stdev: 0.8008\n",
      "Fold 8: 0.7974 (Rank 1) - Stdev: 0.7974\n",
      "Fold 9: 0.8001 (Rank 1) - Stdev: 0.8001\n",
      "Fold 10: 0.8044 (Rank 1) - Stdev: 0.8044\n",
      "Avg: 0.8034 (Avg Rank 1) - Avg Stdev: 0.0039\n",
      "\n",
      "Random Forest Scores, Ranks, and Stdev:\n",
      "Fold 1: 0.9522 (Rank 1) - Stdev: 0.9522\n",
      "Fold 2: 0.9519 (Rank 1) - Stdev: 0.9519\n",
      "Fold 3: 0.9534 (Rank 1) - Stdev: 0.9534\n",
      "Fold 4: 0.9556 (Rank 1) - Stdev: 0.9556\n",
      "Fold 5: 0.9527 (Rank 1) - Stdev: 0.9527\n",
      "Fold 6: 0.9539 (Rank 1) - Stdev: 0.9539\n",
      "Fold 7: 0.9553 (Rank 1) - Stdev: 0.9553\n",
      "Fold 8: 0.9495 (Rank 1) - Stdev: 0.9495\n",
      "Fold 9: 0.9551 (Rank 1) - Stdev: 0.9551\n",
      "Fold 10: 0.9493 (Rank 1) - Stdev: 0.9493\n",
      "Avg: 0.9529 (Avg Rank 1) - Avg Stdev: 0.0021\n",
      "\n",
      "       Decision Tree  k-Nearest Neighbors  Random Forest\n",
      "1           0.921014             0.812077       0.952174\n",
      "2           0.907750             0.803919       0.951942\n",
      "3           0.913065             0.807536       0.953396\n",
      "4           0.914992             0.803186       0.955565\n",
      "5           0.914997             0.801012       0.952669\n",
      "6           0.916687             0.803669       0.953879\n",
      "7           0.918377             0.800770       0.955326\n",
      "8           0.915719             0.797393       0.949525\n",
      "9           0.916199             0.800056       0.955084\n",
      "10          0.904607             0.804391       0.949285\n",
      "avg         0.914341             0.803401       0.952885\n",
      "stdev       0.004608             0.003920       0.002119\n"
     ]
    }
   ],
   "source": [
    "# Initialize an empty DataFrame to store results\n",
    "results_df = pd.DataFrame(index=range(1, 11))\n",
    "\n",
    "# Loop through each fold\n",
    "cv = KFold(n_splits=10, shuffle=True, random_state=42)  # Adjust the parameters as needed\n",
    "for fold, (train_idx, test_idx) in enumerate(cv.split(X), start=1):\n",
    "    # Decision Tree\n",
    "    dt_scores = cross_val_score(dt_model, X.iloc[train_idx], y.iloc[train_idx], cv=cv, scoring='accuracy')\n",
    "    results_df.at[fold, 'Decision Tree'] = dt_scores.mean()\n",
    "    \n",
    "    # KNN\n",
    "    knn_scores = cross_val_score(knn_model, X.iloc[train_idx], y.iloc[train_idx], cv=cv, scoring='accuracy')\n",
    "    results_df.at[fold, 'k-Nearest Neighbors'] = knn_scores.mean()\n",
    "\n",
    "    # Random Forest\n",
    "    rf_scores = cross_val_score(rf_model, X.iloc[train_idx], y.iloc[train_idx], cv=cv, scoring='accuracy')\n",
    "    results_df.at[fold, 'Random Forest'] = rf_scores.mean()\n",
    "\n",
    "# Calculate average and standard deviation\n",
    "results_df.loc['avg', :] = results_df.mean(axis=0)\n",
    "results_df.loc['stdev', :] = results_df.std(axis=0)\n",
    "\n",
    "# Calculate ranks\n",
    "ranks_df = results_df.rank(ascending=False, method='average')\n",
    "\n",
    "# Display the results with ranks and standard deviations\n",
    "for algorithm in results_df.columns:\n",
    "    print(f\"{algorithm} Scores, Ranks, and Stdev:\")\n",
    "    for fold in range(1, 11):\n",
    "        score = results_df.at[fold, algorithm]\n",
    "        rank = rankdata(results_df.loc[fold, algorithm])\n",
    "        stdev = results_df.at[fold, algorithm]\n",
    "        print(f\"Fold {fold}: {score:.4f} (Rank {int(rank)}) - Stdev: {stdev:.4f}\")\n",
    "    avg_score = results_df.at['avg', algorithm]\n",
    "    avg_rank = rankdata(results_df.loc['avg', algorithm])[0]\n",
    "    avg_stdev = results_df.at['stdev', algorithm]\n",
    "    print(f\"Avg: {avg_score:.4f} (Avg Rank {int(avg_rank)}) - Avg Stdev: {avg_stdev:.4f}\\n\")\n",
    "\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Friedman test p-value: 9.611165206139472e-05\n",
      "Critical Difference: 3.7907484397561317\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Conduct the Friedman test\n",
    "_, p_value = friedmanchisquare(\n",
    "    results_df['Decision Tree'], \n",
    "    results_df['k-Nearest Neighbors'], \n",
    "    results_df['Random Forest']\n",
    ")\n",
    "print(f'Friedman test p-value: {p_value}')\n",
    "\n",
    "# If p-value is significant, proceed with Nemenyi test\n",
    "if p_value < 0.05:\n",
    "    # Function to calculate the critical difference using Nemenyi test\n",
    "    def nemenyi_critical_difference(rank_avg, num_algorithms, num_samples):\n",
    "        q_val = chi2.ppf(1 - 0.05 / (2 * num_algorithms * (num_algorithms - 1)) ** 0.5, df=num_algorithms - 1)\n",
    "        return q_val * (num_algorithms * (num_algorithms + 1) / (6 * num_samples)) ** 0.5\n",
    "\n",
    "    # Rank the algorithms\n",
    "    ranks = rankdata(results_df.iloc[:-2, :].values, axis=1).mean(axis=0)\n",
    "\n",
    "    # Calculate critical difference\n",
    "    num_algorithms = results_df.shape[1]\n",
    "    num_samples = results_df.shape[0] - 2\n",
    "    cd = nemenyi_critical_difference(ranks, num_algorithms, num_samples)\n",
    "    print(f'Critical Difference: {cd}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average ranks do not display significant differences.\n"
     ]
    }
   ],
   "source": [
    "# Calculate average ranks\n",
    "average_ranks = rankdata(results_df.iloc[:-2, :].values, axis=1).mean(axis=0)\n",
    "\n",
    "# Calculate rank sums for each algorithm\n",
    "rank_sums = [np.sum(ranks) for ranks in results_df.iloc[:-2, :].values]\n",
    "\n",
    "# Calculate H-statistic for the Kruskal-Wallis test\n",
    "H_statistic, _ = kruskal(*results_df.iloc[:-2, :].values)\n",
    "\n",
    "# Calculate critical value for the Kruskal-Wallis test\n",
    "k = results_df.shape[1]  # Number of algorithms\n",
    "n = results_df.shape[0] - 2  # Number of samples (folds)\n",
    "critical_value = 3.841  # From the chi-squared distribution table for alpha = 0.05 and df = k - 1\n",
    "\n",
    "# Determine whether the average ranks display significant differences\n",
    "if H_statistic > critical_value:\n",
    "    print(\"The average ranks display significant differences.\")\n",
    "\n",
    "    # Use Nemenyi test to calculate critical difference\n",
    "    cd_nemenyi = nemenyi_critical_difference(average_ranks, k, n)\n",
    "    print(f'Critical Difference (Nemenyi): {cd_nemenyi}')\n",
    "\n",
    "    # Identify which algorithms perform significantly differently from each other\n",
    "    significant_pairs = []\n",
    "    for i in range(k - 1):\n",
    "        for j in range(i + 1, k):\n",
    "            diff = np.abs(average_ranks[i] - average_ranks[j])\n",
    "            if diff > cd_nemenyi:\n",
    "                significant_pairs.append((i, j))\n",
    "\n",
    "    print(\"Significantly different algorithm pairs:\")\n",
    "    for pair in significant_pairs:\n",
    "        algorithm1, algorithm2 = pair\n",
    "        print(f\"{results_df.columns[algorithm1]} and {results_df.columns[algorithm2]}\")\n",
    "\n",
    "else:\n",
    "    print(\"The average ranks do not display significant differences.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
