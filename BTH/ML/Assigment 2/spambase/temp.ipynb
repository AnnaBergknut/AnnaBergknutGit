{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Assigment 2\n",
    "Spambase, Anna Bergknut, DVAMI21\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as mpl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as scp\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold, train_test_split\n",
    "\n",
    "from scipy.stats import friedmanchisquare, rankdata, chi2, kruskal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"spambase.data\"\n",
    "columns = ['word_freq_make', 'word_freq_address', 'word_freq_all', 'word_freq_3d', 'word_freq_our', 'word_freq_over', 'word_freq_remove', 'word_freq_internet', 'word_freq_order', 'word_freq_mail', 'word_freq_receive', 'word_freq_will', 'word_freq_people', 'word_freq_report', 'word_freq_addresses', 'word_freq_free', 'word_freq_business', 'word_freq_email', 'word_freq_you', 'word_freq_credit', 'word_freq_your', 'word_freq_font', 'word_freq_000', 'word_freq_money', 'word_freq_hp', 'word_freq_hpl', 'word_freq_george', 'word_freq_650', 'word_freq_lab', 'word_freq_labs', 'word_freq_telnet', 'word_freq_857', 'word_freq_data', 'word_freq_415', 'word_freq_85', 'word_freq_technology', 'word_freq_1999', 'word_freq_parts', 'word_freq_pm', 'word_freq_direct', 'word_freq_cs', 'word_freq_meeting', 'word_freq_original', 'word_freq_project', 'word_freq_re', 'word_freq_edu', 'word_freq_table', 'word_freq_conference', 'charfreq;', 'charfreq(', 'charfreq[', 'charfreq!', 'charfreq$', 'charfreq#', 'capital_run_length_average', 'capital_run_length_longest', 'capital_run_length_total', 'spam/nonspam']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Data\n",
    "data = pd.read_csv(file_path, header=None, names=columns, sep=\",\")\n",
    "\n",
    "# check if null\n",
    "data.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:, :-1]  # Features\n",
    "y = data.iloc[:, -1]   # Target variable\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define 10-fold stratified cross-validation\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74.6 ms ± 284 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "Decision Tree Accuracy: 0.9185667752442996\n",
      "Decision Tree F-Measure: 0.9019607843137256\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree\n",
    "decision_tree_model = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "%timeit decision_tree_model.fit(X_train, y_train)\n",
    "dt_predictions = decision_tree_model.predict(X_test)\n",
    "dt_accuracy = accuracy_score(y_test, dt_predictions)\n",
    "dt_f_measure = f1_score(y_test, dt_predictions, average='binary')\n",
    "print(f'Decision Tree Accuracy: {dt_accuracy}')\n",
    "print(f'Decision Tree F-Measure: {dt_f_measure}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.91 ms ± 206 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "KNN Accuracy: 0.7904451682953312\n",
      "Random Forest F-Measure: 0.7423230974632844\n"
     ]
    }
   ],
   "source": [
    "# k-Nearest Neighbors (KNN)\n",
    "knn_model = KNeighborsClassifier()\n",
    "\n",
    "%timeit knn_model.fit(X_train, y_train)\n",
    "knn_predictions = knn_model.predict(X_test)\n",
    "knn_accuracy = accuracy_score(y_test, knn_predictions)\n",
    "knn_f_measure = f1_score(y_test, knn_predictions)\n",
    "print(f'KNN Accuracy: {knn_accuracy}')\n",
    "print(f'Random Forest F-Measure: {knn_f_measure}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "825 ms ± 15 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "Random Forest Accuracy: 0.9554831704668838\n",
      "Random Forest F-Measure: 0.9458388375165125\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "random_forest_model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "%timeit random_forest_model.fit(X_train, y_train)\n",
    "rf_predictions = random_forest_model.predict(X_test)\n",
    "rf_accuracy = accuracy_score(y_test, rf_predictions)\n",
    "rf_f_measure = f1_score(y_test, rf_predictions, average='binary')\n",
    "print(f'Random Forest Accuracy: {rf_accuracy}')\n",
    "print(f'Random Forest F-Measure: {rf_f_measure}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Decision Tree Training Time  k-Nearest Neighbors Training Time  Random Forest Training Time  Decision Tree Accuracy  Decision Tree F-Measure  k-Nearest Neighbors Accuracy  k-Nearest Neighbors F-Measure  Random Forest Accuracy  Random Forest F-Measure\n",
      "1                         0.076752                           0.002558                     0.860316                     NaN                      NaN                           NaN                            NaN                     NaN                      NaN\n",
      "2                         0.077361                           0.003001                     0.821040                     NaN                      NaN                           NaN                            NaN                     NaN                      NaN\n",
      "3                         0.075013                           0.001967                     0.831409                     NaN                      NaN                           NaN                            NaN                     NaN                      NaN\n",
      "4                         0.075466                           0.004011                     0.824210                     NaN                      NaN                           NaN                            NaN                     NaN                      NaN\n",
      "5                         0.074436                           0.001987                     0.832888                     NaN                      NaN                           NaN                            NaN                     NaN                      NaN\n",
      "6                         0.076364                           0.004001                     0.835213                     NaN                      NaN                           NaN                            NaN                     NaN                      NaN\n",
      "7                         0.074442                           0.002551                     0.812553                     NaN                      NaN                           NaN                            NaN                     NaN                      NaN\n",
      "8                         0.073830                           0.003564                     0.816178                     NaN                      NaN                           NaN                            NaN                     NaN                      NaN\n",
      "9                         0.077970                           0.002007                     0.873865                     NaN                      NaN                           NaN                            NaN                     NaN                      NaN\n",
      "10                        0.075685                           0.003514                     0.868376                0.918567                 0.901961                      0.790445                       0.742323                0.955483                 0.945839\n",
      "avg                       0.075732                           0.002916                     0.837605                0.918567                 0.901961                      0.790445                       0.742323                0.955483                 0.945839\n",
      "stdev                     0.001290                           0.000775                     0.020939                0.000000                 0.000000                      0.000000                       0.000000                0.000000                 0.000000\n"
     ]
    }
   ],
   "source": [
    "# Initialize an empty DataFrame to store results\n",
    "results_df = pd.DataFrame(index=range(1, 11))\n",
    "\n",
    "# Loop through each fold\n",
    "for fold in range(1, 11):\n",
    "    \n",
    "    # Decision Tree\n",
    "    start_time = time.time()\n",
    "    decision_tree_model.fit(X_train, y_train)\n",
    "    training_time = time.time() - start_time\n",
    "    results_df.at[fold, 'Decision Tree Training Time'] = training_time\n",
    "\n",
    "    # KNN\n",
    "    start_time = time.time()\n",
    "    knn_model.fit(X_train, y_train)\n",
    "    training_time = time.time() - start_time\n",
    "    results_df.at[fold, 'k-Nearest Neighbors Training Time'] = training_time\n",
    "\n",
    "    # Random Forest\n",
    "    start_time = time.time()\n",
    "    random_forest_model.fit(X_train, y_train)\n",
    "    training_time = time.time() - start_time\n",
    "    results_df.at[fold, 'Random Forest Training Time'] = training_time\n",
    "\n",
    "# Add accuracy and F-measure columns for each algorithm\n",
    "for algorithm in ['Decision Tree', 'k-Nearest Neighbors', 'Random Forest']:\n",
    "    model_name = f\"{algorithm.replace(' ', '_').lower()}_model\"\n",
    "    if algorithm == 'k-Nearest Neighbors':\n",
    "        model_name = 'knn_model'\n",
    "    \n",
    "    predictions = globals()[model_name].predict(X_test)\n",
    "    results_df.at[fold, f'{algorithm} Accuracy'] = accuracy_score(y_test, predictions)\n",
    "    results_df.at[fold, f'{algorithm} F-Measure'] = f1_score(y_test, predictions, average='binary')\n",
    "    \n",
    "# Calculate average and standard deviation\n",
    "results_df.at['avg', :] = results_df.mean(axis=0)\n",
    "results_df.at['stdev', :] = results_df.std(axis=0)\n",
    "\n",
    "# Display the results table\n",
    "print(results_df.to_string())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Friedman test p-value: 1.5366306526875732e-05\n",
      "Critical Difference: 3.7907484397561317\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Conduct the Friedman test\n",
    "_, p_value = friedmanchisquare(\n",
    "    results_df['Decision Tree'], \n",
    "    results_df['k-Nearest Neighbors'], \n",
    "    results_df['Random Forest']\n",
    ")\n",
    "print(f'Friedman test p-value: {p_value}')\n",
    "\n",
    "# If p-value is significant, proceed with Nemenyi test\n",
    "if p_value < 0.05:\n",
    "    # Function to calculate the critical difference using Nemenyi test\n",
    "    def nemenyi_critical_difference(rank_avg, num_algorithms, num_samples):\n",
    "        q_val = chi2.ppf(1 - 0.05 / (2 * num_algorithms * (num_algorithms - 1)) ** 0.5, df=num_algorithms - 1)\n",
    "        return q_val * (num_algorithms * (num_algorithms + 1) / (6 * num_samples)) ** 0.5\n",
    "\n",
    "    # Rank the algorithms\n",
    "    ranks = rankdata(results_df.iloc[:-2, :].values, axis=1).mean(axis=0)\n",
    "\n",
    "    # Calculate critical difference\n",
    "    num_algorithms = results_df.shape[1]\n",
    "    num_samples = results_df.shape[0] - 2\n",
    "    cd = nemenyi_critical_difference(ranks, num_algorithms, num_samples)\n",
    "    print(f'Critical Difference: {cd}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average ranks do not display significant differences.\n"
     ]
    }
   ],
   "source": [
    "# Calculate average ranks\n",
    "average_ranks = rankdata(results_df.iloc[:-2, :].values, axis=1).mean(axis=0)\n",
    "\n",
    "# Calculate rank sums for each algorithm\n",
    "rank_sums = [np.sum(ranks) for ranks in results_df.iloc[:-2, :].values]\n",
    "\n",
    "# Calculate H-statistic for the Kruskal-Wallis test\n",
    "H_statistic, _ = kruskal(*results_df.iloc[:-2, :].values)\n",
    "\n",
    "# Calculate critical value for the Kruskal-Wallis test\n",
    "k = results_df.shape[1]  # Number of algorithms\n",
    "n = results_df.shape[0] - 2  # Number of samples (folds)\n",
    "critical_value = 3.841  # From the chi-squared distribution table for alpha = 0.05 and df = k - 1\n",
    "\n",
    "# Determine whether the average ranks display significant differences\n",
    "if H_statistic > critical_value:\n",
    "    print(\"The average ranks display significant differences.\")\n",
    "\n",
    "    # Use Nemenyi test to calculate critical difference\n",
    "    cd_nemenyi = nemenyi_critical_difference(average_ranks, k, n)\n",
    "    print(f'Critical Difference (Nemenyi): {cd_nemenyi}')\n",
    "\n",
    "    # Identify which algorithms perform significantly differently from each other\n",
    "    significant_pairs = []\n",
    "    for i in range(k - 1):\n",
    "        for j in range(i + 1, k):\n",
    "            diff = np.abs(average_ranks[i] - average_ranks[j])\n",
    "            if diff > cd_nemenyi:\n",
    "                significant_pairs.append((i, j))\n",
    "\n",
    "    print(\"Significantly different algorithm pairs:\")\n",
    "    for pair in significant_pairs:\n",
    "        algorithm1, algorithm2 = pair\n",
    "        print(f\"{results_df.columns[algorithm1]} and {results_df.columns[algorithm2]}\")\n",
    "\n",
    "else:\n",
    "    print(\"The average ranks do not display significant differences.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
